{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:, i, :, :].mean()\n",
    "            std[i] += inputs[:, i, :, :].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Check devices..\n",
      "Current device:  cuda\n",
      "Our selected device:  0\n",
      "1  GPUs is available\n"
     ]
    }
   ],
   "source": [
    "#To determine if your system supports CUDA\n",
    "print(\"==> Check devices..\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Current device: \",device)\n",
    "\n",
    "#Also can print your current GPU id, and the number of GPUs you can use.\n",
    "print(\"Our selected device: \", torch.cuda.current_device())\n",
    "print(torch.cuda.device_count(), \" GPUs is available\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset..\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing dataset..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing mean and std..\n",
      "tensor([0.5548, 0.4476, 0.3364]) tensor([0.2336, 0.2413, 0.2384])\n",
      "==> Computing mean and std..\n",
      "tensor([0.5592, 0.4504, 0.3416]) tensor([0.2326, 0.2405, 0.2369])\n",
      "==> Computing mean and std..\n",
      "tensor([0.5609, 0.4524, 0.3431]) tensor([0.2334, 0.2417, 0.2391])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"1.1\"\"\"\n",
    "#img_size, linear_size, fc1_out, fc2_out = 64, 13, 128, 84\n",
    "#img_size, linear_size, fc1_out, fc2_out = 64, 13, 128, 84\n",
    "#img_size, linear_size, fc1_out, fc2_out = 128, 29, 256, 84\n",
    "#img_size, linear_size, fc1_out, fc2_out = 256, 61, 256, 84\n",
    "#img_size, linear_size, fc1_out, fc2_out = 384, 93, 128, 84\n",
    "img_size, linear_size, fc1_out, fc2_out = 384, 21, 128, 84\n",
    "#img_size, linear_size, fc1_out, fc2_out = 512, 125, 256, 84\n",
    "#img_size, linear_size, fc1_out, fc2_out = 512, 125, 512, 84\n",
    "#img_size, linear_size, fc1_out, fc2_out = 1024, 253, 256, 84\n",
    "\n",
    "calculate_mean_std = True\n",
    "\n",
    "if calculate_mean_std == True:\n",
    "    #The transform function for train data\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomCrop(img_size, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomCrop(img_size, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    #The transform function for test data\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomCrop(img_size, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    #we will calculate mean and std\n",
    "    \n",
    "    trainset = torchvision.datasets.ImageFolder(root='./food/training', transform=transform_train)\n",
    "    valset = torchvision.datasets.ImageFolder(root='./food/validation', transform=transform_val)\n",
    "    testset = torchvision.datasets.ImageFolder(root='./food/evaluation', transform=transform_test)\n",
    "    \n",
    "    train_mean, train_std = get_mean_and_std(trainset)\n",
    "    print(train_mean, train_std)\n",
    "    val_mean, val_std = get_mean_and_std(valset)\n",
    "    print(val_mean, val_std)\n",
    "    test_mean, test_std = get_mean_and_std(testset)\n",
    "    print(test_mean, test_std)\n",
    "else:\n",
    "    train_mean, train_std = ([0.5551, 0.4478, 0.3366]), ([0.2337, 0.2414, 0.2386])\n",
    "    val_mean, val_std = ([0.5292, 0.4256, 0.3189]), ([0.2494, 0.2442, 0.2316])\n",
    "    test_mean, test_std = ([0.5607, 0.4518, 0.3425]), ([0.2333, 0.2415, 0.2385])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"1.1+\"\"\"\n",
    "#The transform function for train data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomCrop(img_size, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "#The transform function for validation data\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomCrop(img_size, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(val_mean, val_std)\n",
    "])\n",
    "\n",
    "#The transform function for test data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomCrop(img_size, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(test_mean, test_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"1.2+\"\"\"\n",
    "trainset = torchvision.datasets.ImageFolder(root='./food/training', transform=transform_train)\n",
    "valset = torchvision.datasets.ImageFolder(root='./food/validation', transform=transform_val)\n",
    "testset = torchvision.datasets.ImageFolder(root='./food/evaluation', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"1.3\"\"\"\n",
    "\n",
    "#Create DataLoader to draw samples from the dataset\n",
    "#In this case, we define a DataLoader to random sample our dataset. \n",
    "#For single sampling, we take one batch of data. Each batch consists 4 images\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=32,\n",
    "shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ('Bread', 'DairyProduct', 'Dessert', 'Egg', 'Friedfood',\n",
    "           'Meat', 'Noodles-Pasta', 'Rice', 'Seafood', 'Soup', 'Vegetable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define your own model\n",
    "class Net(nn.Module):\n",
    "\n",
    "    #define the layers\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 3)\n",
    "        self.conv4 = nn.Conv2d(16, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * linear_size * linear_size, fc1_out)\n",
    "        self.fc2 = nn.Linear(fc1_out, fc2_out)\n",
    "        self.fc3 = nn.Linear(fc2_out, 11)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    #concatenate these layers\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 16 * linear_size * linear_size)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#declare a new model\n",
    "net = Net()\n",
    "# change all model tensor into cuda type\n",
    "# something like weight & bias are the tensor \n",
    "#net = net.to(device)\n",
    "print(device)\n",
    "if device == 'cuda':\n",
    "    net = net.cuda(0)\n",
    "else:\n",
    "    net = net.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "\n",
    "# 3. Define a Loss function and optimize\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Defining loss function and optimize..\n"
     ]
    }
   ],
   "source": [
    "print('==> Defining loss function and optimize..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimization algorithm\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "\n",
    "# 4. Train the network\n",
    "\n",
    "Before training the model, we need to analysis the tensor variable.\n",
    "\n",
    "\n",
    "Each variable have many attibute, like: .grad_fn, .require_grad, .data, .grad...etc. The \".grad_fn\" attribute of \"torch.Tensor\" is an entry point into the function that has create this \"torch.Tensor\" variables. Because of \".grad_fn\" flag, we can easily create a computing graph in the form of DAG(directed acyclic graph).\n",
    "\n",
    "And then, the \".require_grad\" attribute allows us to determine whether the backward propagation function is going to calculate the gradient of this \"torch.Tensor\" variable. If one variable has a false value of require_grad, it represent that you don't want to calculate this variable's gradient, and also its gradient will not be updated.\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Training model..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "for phase in ['train', 'val']:\n",
    "    if phase == 'train':\n",
    "        print(phase)    \n",
    "    else:\n",
    "        print(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Epoch ss Loss: 1.2000 Acc: 1.3000\n"
     ]
    }
   ],
   "source": [
    "print('{:d} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(1, 'ss', 1.2, 1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Epoch train Loss: 0.0684 Acc: 0.2174\n",
      "0 Epoch val Loss: 0.0680 Acc: 0.2204\n",
      "1 Epoch train Loss: 0.0669 Acc: 0.2416\n",
      "1 Epoch val Loss: 0.0662 Acc: 0.2571\n",
      "2 Epoch train Loss: 0.0649 Acc: 0.2745\n",
      "2 Epoch val Loss: 0.0645 Acc: 0.2691\n",
      "3 Epoch train Loss: 0.0637 Acc: 0.2877\n",
      "3 Epoch val Loss: 0.0642 Acc: 0.2761\n",
      "4 Epoch train Loss: 0.0628 Acc: 0.2907\n",
      "4 Epoch val Loss: 0.0638 Acc: 0.2857\n",
      "5 Epoch train Loss: 0.0621 Acc: 0.3007\n",
      "5 Epoch val Loss: 0.0625 Acc: 0.2959\n",
      "6 Epoch train Loss: 0.0612 Acc: 0.3087\n",
      "6 Epoch val Loss: 0.0621 Acc: 0.3108\n",
      "7 Epoch train Loss: 0.0600 Acc: 0.3263\n",
      "7 Epoch val Loss: 0.0606 Acc: 0.3105\n",
      "8 Epoch train Loss: 0.0580 Acc: 0.3465\n",
      "8 Epoch val Loss: 0.0586 Acc: 0.3376\n",
      "9 Epoch train Loss: 0.0560 Acc: 0.3764\n",
      "9 Epoch val Loss: 0.0587 Acc: 0.3481\n",
      "10 Epoch train Loss: 0.0551 Acc: 0.3849\n",
      "10 Epoch val Loss: 0.0561 Acc: 0.3706\n",
      "11 Epoch train Loss: 0.0543 Acc: 0.3976\n",
      "11 Epoch val Loss: 0.0558 Acc: 0.3819\n",
      "12 Epoch train Loss: 0.0531 Acc: 0.4070\n",
      "12 Epoch val Loss: 0.0551 Acc: 0.3904\n",
      "13 Epoch train Loss: 0.0521 Acc: 0.4221\n",
      "13 Epoch val Loss: 0.0554 Acc: 0.3930\n",
      "14 Epoch train Loss: 0.0513 Acc: 0.4274\n",
      "14 Epoch val Loss: 0.0538 Acc: 0.4061\n",
      "15 Epoch train Loss: 0.0504 Acc: 0.4441\n",
      "15 Epoch val Loss: 0.0545 Acc: 0.4122\n",
      "16 Epoch train Loss: 0.0490 Acc: 0.4533\n",
      "16 Epoch val Loss: 0.0527 Acc: 0.4233\n",
      "17 Epoch train Loss: 0.0483 Acc: 0.4683\n",
      "17 Epoch val Loss: 0.0525 Acc: 0.4195\n",
      "18 Epoch train Loss: 0.0471 Acc: 0.4811\n",
      "18 Epoch val Loss: 0.0527 Acc: 0.4254\n",
      "19 Epoch train Loss: 0.0463 Acc: 0.4882\n",
      "19 Epoch val Loss: 0.0529 Acc: 0.4236\n",
      "20 Epoch train Loss: 0.0447 Acc: 0.5090\n",
      "20 Epoch val Loss: 0.0515 Acc: 0.4411\n",
      "21 Epoch train Loss: 0.0434 Acc: 0.5188\n",
      "21 Epoch val Loss: 0.0503 Acc: 0.4504\n",
      "22 Epoch train Loss: 0.0423 Acc: 0.5395\n",
      "22 Epoch val Loss: 0.0521 Acc: 0.4370\n",
      "23 Epoch train Loss: 0.0411 Acc: 0.5456\n",
      "23 Epoch val Loss: 0.0506 Acc: 0.4513\n",
      "24 Epoch train Loss: 0.0400 Acc: 0.5619\n",
      "24 Epoch val Loss: 0.0516 Acc: 0.4434\n",
      "25 Epoch train Loss: 0.0388 Acc: 0.5785\n",
      "25 Epoch val Loss: 0.0529 Acc: 0.4399\n",
      "26 Epoch train Loss: 0.0370 Acc: 0.6008\n",
      "26 Epoch val Loss: 0.0527 Acc: 0.4542\n",
      "27 Epoch train Loss: 0.0361 Acc: 0.6079\n",
      "27 Epoch val Loss: 0.0578 Acc: 0.4184\n",
      "28 Epoch train Loss: 0.0349 Acc: 0.6209\n",
      "28 Epoch val Loss: 0.0527 Acc: 0.4504\n",
      "29 Epoch train Loss: 0.0338 Acc: 0.6356\n",
      "29 Epoch val Loss: 0.0558 Acc: 0.4490\n",
      "30 Epoch train Loss: 0.0324 Acc: 0.6552\n",
      "30 Epoch val Loss: 0.0543 Acc: 0.4519\n",
      "31 Epoch train Loss: 0.0315 Acc: 0.6677\n",
      "31 Epoch val Loss: 0.0568 Acc: 0.4566\n",
      "32 Epoch train Loss: 0.0302 Acc: 0.6809\n",
      "32 Epoch val Loss: 0.0559 Acc: 0.4434\n",
      "33 Epoch train Loss: 0.0294 Acc: 0.6946\n",
      "33 Epoch val Loss: 0.0572 Acc: 0.4359\n",
      "34 Epoch train Loss: 0.0284 Acc: 0.7056\n",
      "34 Epoch val Loss: 0.0557 Acc: 0.4420\n",
      "35 Epoch train Loss: 0.0273 Acc: 0.7177\n",
      "35 Epoch val Loss: 0.0588 Acc: 0.4475\n",
      "36 Epoch train Loss: 0.0269 Acc: 0.7235\n",
      "36 Epoch val Loss: 0.0562 Acc: 0.4475\n",
      "37 Epoch train Loss: 0.0249 Acc: 0.7430\n",
      "37 Epoch val Loss: 0.0571 Acc: 0.4630\n",
      "38 Epoch train Loss: 0.0237 Acc: 0.7554\n",
      "38 Epoch val Loss: 0.0597 Acc: 0.4501\n",
      "39 Epoch train Loss: 0.0232 Acc: 0.7633\n",
      "39 Epoch val Loss: 0.0589 Acc: 0.4501\n",
      "40 Epoch train Loss: 0.0227 Acc: 0.7714\n",
      "40 Epoch val Loss: 0.0627 Acc: 0.4507\n",
      "41 Epoch train Loss: 0.0220 Acc: 0.7818\n",
      "41 Epoch val Loss: 0.0626 Acc: 0.4455\n",
      "42 Epoch train Loss: 0.0212 Acc: 0.7901\n",
      "42 Epoch val Loss: 0.0613 Acc: 0.4603\n",
      "43 Epoch train Loss: 0.0211 Acc: 0.7907\n",
      "43 Epoch val Loss: 0.0668 Acc: 0.4545\n",
      "44 Epoch train Loss: 0.0204 Acc: 0.7937\n",
      "44 Epoch val Loss: 0.0644 Acc: 0.4487\n",
      "45 Epoch train Loss: 0.0195 Acc: 0.8083\n",
      "45 Epoch val Loss: 0.0666 Acc: 0.4525\n",
      "46 Epoch train Loss: 0.0193 Acc: 0.8054\n",
      "46 Epoch val Loss: 0.0656 Acc: 0.4563\n",
      "47 Epoch train Loss: 0.0188 Acc: 0.8099\n",
      "47 Epoch val Loss: 0.0654 Acc: 0.4571\n",
      "48 Epoch train Loss: 0.0181 Acc: 0.8241\n",
      "48 Epoch val Loss: 0.0665 Acc: 0.4551\n",
      "49 Epoch train Loss: 0.0175 Acc: 0.8282\n",
      "49 Epoch val Loss: 0.0656 Acc: 0.4589\n",
      "50 Epoch train Loss: 0.0175 Acc: 0.8235\n",
      "50 Epoch val Loss: 0.0690 Acc: 0.4569\n",
      "51 Epoch train Loss: 0.0170 Acc: 0.8274\n",
      "51 Epoch val Loss: 0.0665 Acc: 0.4647\n",
      "52 Epoch train Loss: 0.0164 Acc: 0.8331\n",
      "52 Epoch val Loss: 0.0764 Acc: 0.4379\n",
      "53 Epoch train Loss: 0.0168 Acc: 0.8306\n",
      "53 Epoch val Loss: 0.0710 Acc: 0.4370\n",
      "54 Epoch train Loss: 0.0154 Acc: 0.8495\n",
      "54 Epoch val Loss: 0.0670 Acc: 0.4601\n",
      "55 Epoch train Loss: 0.0157 Acc: 0.8429\n",
      "55 Epoch val Loss: 0.0711 Acc: 0.4563\n",
      "56 Epoch train Loss: 0.0148 Acc: 0.8533\n",
      "56 Epoch val Loss: 0.0690 Acc: 0.4499\n",
      "57 Epoch train Loss: 0.0149 Acc: 0.8517\n",
      "57 Epoch val Loss: 0.0701 Acc: 0.4484\n",
      "58 Epoch train Loss: 0.0145 Acc: 0.8618\n",
      "58 Epoch val Loss: 0.0732 Acc: 0.4601\n",
      "59 Epoch train Loss: 0.0141 Acc: 0.8592\n",
      "59 Epoch val Loss: 0.0734 Acc: 0.4641\n",
      "60 Epoch train Loss: 0.0133 Acc: 0.8683\n",
      "60 Epoch val Loss: 0.0789 Acc: 0.4513\n",
      "61 Epoch train Loss: 0.0134 Acc: 0.8662\n",
      "61 Epoch val Loss: 0.0730 Acc: 0.4606\n",
      "62 Epoch train Loss: 0.0131 Acc: 0.8684\n",
      "62 Epoch val Loss: 0.0754 Acc: 0.4595\n",
      "63 Epoch train Loss: 0.0132 Acc: 0.8700\n",
      "63 Epoch val Loss: 0.0762 Acc: 0.4603\n",
      "64 Epoch train Loss: 0.0125 Acc: 0.8766\n",
      "64 Epoch val Loss: 0.0779 Acc: 0.4647\n",
      "65 Epoch train Loss: 0.0123 Acc: 0.8791\n",
      "65 Epoch val Loss: 0.0786 Acc: 0.4656\n",
      "66 Epoch train Loss: 0.0123 Acc: 0.8761\n",
      "66 Epoch val Loss: 0.0743 Acc: 0.4577\n",
      "67 Epoch train Loss: 0.0113 Acc: 0.8874\n",
      "67 Epoch val Loss: 0.0784 Acc: 0.4612\n",
      "68 Epoch train Loss: 0.0117 Acc: 0.8830\n",
      "68 Epoch val Loss: 0.0798 Acc: 0.4516\n",
      "69 Epoch train Loss: 0.0114 Acc: 0.8842\n",
      "69 Epoch val Loss: 0.0787 Acc: 0.4653\n",
      "70 Epoch train Loss: 0.0110 Acc: 0.8884\n",
      "70 Epoch val Loss: 0.0782 Acc: 0.4501\n",
      "71 Epoch train Loss: 0.0104 Acc: 0.8983\n",
      "71 Epoch val Loss: 0.0825 Acc: 0.4615\n",
      "72 Epoch train Loss: 0.0108 Acc: 0.8934\n",
      "72 Epoch val Loss: 0.0806 Acc: 0.4569\n",
      "73 Epoch train Loss: 0.0100 Acc: 0.8983\n",
      "73 Epoch val Loss: 0.0855 Acc: 0.4563\n",
      "74 Epoch train Loss: 0.0105 Acc: 0.8952\n",
      "74 Epoch val Loss: 0.0800 Acc: 0.4656\n",
      "75 Epoch train Loss: 0.0104 Acc: 0.8941\n",
      "75 Epoch val Loss: 0.0850 Acc: 0.4571\n",
      "76 Epoch train Loss: 0.0103 Acc: 0.8956\n",
      "76 Epoch val Loss: 0.0858 Acc: 0.4402\n",
      "77 Epoch train Loss: 0.0102 Acc: 0.9000\n",
      "77 Epoch val Loss: 0.0864 Acc: 0.4630\n",
      "78 Epoch train Loss: 0.0099 Acc: 0.9042\n",
      "78 Epoch val Loss: 0.0787 Acc: 0.4656\n",
      "79 Epoch train Loss: 0.0093 Acc: 0.9055\n",
      "79 Epoch val Loss: 0.0860 Acc: 0.4545\n",
      "80 Epoch train Loss: 0.0098 Acc: 0.9010\n",
      "80 Epoch val Loss: 0.0874 Acc: 0.4469\n",
      "81 Epoch train Loss: 0.0092 Acc: 0.9072\n",
      "81 Epoch val Loss: 0.0867 Acc: 0.4673\n",
      "82 Epoch train Loss: 0.0088 Acc: 0.9129\n",
      "82 Epoch val Loss: 0.0864 Acc: 0.4542\n",
      "83 Epoch train Loss: 0.0096 Acc: 0.9049\n",
      "83 Epoch val Loss: 0.0830 Acc: 0.4603\n",
      "84 Epoch train Loss: 0.0094 Acc: 0.9071\n",
      "84 Epoch val Loss: 0.0862 Acc: 0.4513\n",
      "85 Epoch train Loss: 0.0090 Acc: 0.9091\n",
      "85 Epoch val Loss: 0.0908 Acc: 0.4691\n",
      "86 Epoch train Loss: 0.0087 Acc: 0.9136\n",
      "86 Epoch val Loss: 0.0896 Acc: 0.4496\n",
      "87 Epoch train Loss: 0.0089 Acc: 0.9089\n",
      "87 Epoch val Loss: 0.0865 Acc: 0.4638\n",
      "88 Epoch train Loss: 0.0079 Acc: 0.9234\n",
      "88 Epoch val Loss: 0.0957 Acc: 0.4598\n",
      "89 Epoch train Loss: 0.0079 Acc: 0.9198\n",
      "89 Epoch val Loss: 0.0867 Acc: 0.4685\n",
      "90 Epoch train Loss: 0.0078 Acc: 0.9193\n",
      "90 Epoch val Loss: 0.0978 Acc: 0.4499\n",
      "91 Epoch train Loss: 0.0079 Acc: 0.9215\n",
      "91 Epoch val Loss: 0.0926 Acc: 0.4525\n",
      "92 Epoch train Loss: 0.0074 Acc: 0.9239\n",
      "92 Epoch val Loss: 0.0916 Acc: 0.4682\n",
      "93 Epoch train Loss: 0.0076 Acc: 0.9251\n",
      "93 Epoch val Loss: 0.0950 Acc: 0.4580\n",
      "94 Epoch train Loss: 0.0077 Acc: 0.9238\n",
      "94 Epoch val Loss: 0.0930 Acc: 0.4554\n",
      "95 Epoch train Loss: 0.0080 Acc: 0.9164\n",
      "95 Epoch val Loss: 0.0921 Acc: 0.4598\n",
      "96 Epoch train Loss: 0.0073 Acc: 0.9292\n",
      "96 Epoch val Loss: 0.0934 Acc: 0.4574\n",
      "97 Epoch train Loss: 0.0071 Acc: 0.9284\n",
      "97 Epoch val Loss: 0.0998 Acc: 0.4656\n",
      "98 Epoch train Loss: 0.0072 Acc: 0.9269\n",
      "98 Epoch val Loss: 0.0957 Acc: 0.4603\n",
      "99 Epoch train Loss: 0.0075 Acc: 0.9244\n",
      "99 Epoch val Loss: 0.0906 Acc: 0.4621\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Set the model in training mode\n",
    "#because some function like: dropout, batchnorm...etc, will have \n",
    "#different behaviors in training/evaluation mode\n",
    "#[document]: https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train\n",
    "import copy\n",
    "\n",
    "best_model = net\n",
    "best_acc = 0.0\n",
    "\n",
    "net.train()\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.5)\n",
    "\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            net.train(True)  # Set model to training mode\n",
    "            dset_loaders = trainloader\n",
    "        else:\n",
    "            net.train(False)  # Set model to evaluate mode\n",
    "            dset_loaders = valloader\n",
    "            \n",
    "        #scheduler.step()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        \n",
    "        for data in dset_loaders:\n",
    "        \n",
    "            (inputs, labels) = data\n",
    "            \n",
    "            #change the type into cuda tensor \n",
    "            if device == 'cuda':\n",
    "                inputs = inputs.cuda(0)\n",
    "                labels = labels.cuda(0)\n",
    "            else:\n",
    "                inputs = inputs.cpu()\n",
    "                labels = labels.cpu()\n",
    "\n",
    "            #print(labels)\n",
    "            #print(inputs)\n",
    "        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            # select the class with highest probability\n",
    "            _, pred = outputs.max(1)\n",
    "            # if the model predicts the same results as the true\n",
    "            # label, then the correct counter will plus 1\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "        \n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        if phase == 'train':\n",
    "            epoch_loss = running_loss / len(trainset)\n",
    "            epoch_acc = correct / len(trainset)\n",
    "        else:\n",
    "            epoch_loss = running_loss / len(valset)\n",
    "            epoch_acc = correct / len(valset)\n",
    "\n",
    "        print('{:d} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(epoch, phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(net)\n",
    "print('Finished Training')\n",
    "\n",
    "net = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccma/anaconda3/lib/python3.5/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nepkgJEm9TBCSpF4mCElSLxOEJKnX/wfGF1FlRGulwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxszMcudkY2ZmuXOyMTOz3P0345wEmrw8aHYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_conv_weight_distribution():\n",
    "    for i in range(1, 3):\n",
    "        ax = plt.subplot(1, 2, i)\n",
    "        #ax.set_ylim([0, 20000])\n",
    "        plt.grid(False)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    x = net.conv1.weight.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('conv1')\n",
    "    plt.ylabel('Probability')\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    x = net.conv2.weight.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('conv2')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def show_fc_weight_distribution():\n",
    "    for i in range(1, 4):\n",
    "        ax = plt.subplot(1, 3, i)\n",
    "        #ax.set_ylim([0, 20000])\n",
    "        plt.grid(False)\n",
    "\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    x = net.fc1.weight.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('fc1')\n",
    "    plt.ylabel('Probability')\n",
    "\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    x = net.fc2.weight.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('fc2')\n",
    "\n",
    "    ax = plt.subplot(1, 3, 3)\n",
    "    x = net.fc3.weight.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('fc3')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_conv_weight_distribution()\n",
    "show_fc_weight_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccma/anaconda3/lib/python3.5/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAVJUuv/AyLsUFi+ebuGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_conv_bias_distribution():\n",
    "    for i in range(1, 3):\n",
    "        ax = plt.subplot(1, 2, i)\n",
    "        #ax.set_ylim([0, 20000])\n",
    "        plt.grid(False)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    x = net.conv1.bias.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('conv1')\n",
    "    plt.ylabel('Probability')\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    x = net.conv2.bias.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('conv2')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def show_fc_bias_distribution():\n",
    "    for i in range(1, 4):\n",
    "        ax = plt.subplot(1, 3, i)\n",
    "        #ax.set_ylim([0, 20000])\n",
    "        plt.grid(False)\n",
    "\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    x = net.fc1.bias.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('fc1')\n",
    "    plt.ylabel('Probability')\n",
    "\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    x = net.fc2.bias.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('fc2')\n",
    "\n",
    "    ax = plt.subplot(1, 3, 3)\n",
    "    x = net.fc3.bias.view(-1,1).cpu().detach().numpy()\n",
    "    n, bins, patches = plt.hist(x, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('fc3')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_conv_bias_distribution()\n",
    "show_fc_bias_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving model..\n",
      "Finished Saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccma/anaconda3/lib/python3.5/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#After training , save the model first\n",
    "#You can saves only the model parameters or entire model\n",
    "#Some difference between the two is that entire model \n",
    "#not only include parameters but also record hwo each \n",
    "#layer is connected(forward method).\n",
    "#[document]: https://pytorch.org/docs/master/notes/serialization.html\n",
    "\n",
    "print('==> Saving model..')\n",
    "\n",
    "#only save model parameters\n",
    "torch.save(net.state_dict(), './checkpoint.t7')\n",
    "#you also can store some log information\n",
    "state = {\n",
    "    'net': net.state_dict(),\n",
    "    'acc': 100.*correct/len(trainset),\n",
    "    'epoch': 75\n",
    "}\n",
    "torch.save(state, './checkpoint.t7')\n",
    "\n",
    "#save entire model\n",
    "torch.save(net, './model.pt')\n",
    "\n",
    "print('Finished Saving')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "\n",
    "# 5. Test the network on the test data\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Before testing, we can load the saved model\n",
    "#Depend on how you save your model, need \n",
    "#different way to use it\n",
    "\n",
    "print('==> Loading model..')\n",
    "\n",
    "#If you just save the model parameters, you\n",
    "#need to redefine the model architecture, and\n",
    "#load the parameters into your model\n",
    "net = Net()\n",
    "checkpoint = torch.load('./checkpoint.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "#If you save the entire model\n",
    "net = torch.load('./model.pt')\n",
    "\n",
    "print('Finished Loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Testing model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=7056, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=11, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('==> Testing model..')\n",
    "\n",
    "#Set the model in evaluation mode\n",
    "#[document]: https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval \n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 3347 test images: 49.39%, and loss is: 0.083\n",
      "Accuracy of Bread : 39 %\n",
      "Accuracy of DairyProduct : 22 %\n",
      "Accuracy of Dessert : 80 %\n",
      "Accuracy of   Egg : 44 %\n",
      "Accuracy of Friedfood : 26 %\n",
      "Accuracy of  Meat : 33 %\n",
      "Accuracy of Noodles-Pasta : 59 %\n",
      "Accuracy of  Rice : 53 %\n",
      "Accuracy of Seafood : 48 %\n",
      "Accuracy of  Soup : 43 %\n",
      "Accuracy of Vegetable : 73 %\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#######LAB 1-1########\n",
    "\"\"\"\n",
    "To Do Here\n",
    "\n",
    "        You should complete the testing step in LAB 1-1\n",
    "You should show the total accuracy & loss [10000 cifar10 test cases]\n",
    "  You also need to tell us, how about the accuracy for each class\n",
    " \n",
    "    For example: Total accuracy is: 60.0% and loss is: 0.02  \n",
    "                 For each class in cifar 10:\n",
    "                 Accuracy of plane : 58.0%\n",
    "                 Accuracy of   car : 22.4%\n",
    "                            .\n",
    "                            .\n",
    "                            .\n",
    "\"\"\"\n",
    "######################\n",
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "\n",
    "class_correct = list(0. for i in range(11))\n",
    "class_total = list(0. for i in range(11))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "\n",
    "        if device == 'cuda':\n",
    "            images = images.cuda(0)\n",
    "            labels = labels.cuda(0)\n",
    "        else:\n",
    "            images = images.cpu()\n",
    "            labels = labels.cpu()\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        c = (predicted == labels).squeeze()\n",
    "        #print(predicted)\n",
    "        #print(labels.size(0))\n",
    "        #print(c)\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %.2f%%, and loss is: %.3f'\n",
    "      % (total, 100 * correct / total, running_loss / total))\n",
    "\n",
    "for i in range(11):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
